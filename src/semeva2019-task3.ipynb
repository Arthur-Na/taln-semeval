{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/kutilities/callbacks.py:6: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  matplotlib.use('TkAgg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.constraints import maxnorm\n",
    "from keras.engine import Input\n",
    "from keras.engine import Model\n",
    "from keras.layers import Dropout, Dense, Bidirectional, LSTM, \\\n",
    "    Embedding, GaussianNoise, Activation, Flatten, \\\n",
    "    RepeatVector, MaxoutDense, GlobalMaxPooling1D, \\\n",
    "    Convolution1D, MaxPooling1D, concatenate, Conv1D, GRU, Flatten, MaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from kutilities.layers import AttentionWithContext, Attention, MeanOverTime\n",
    "from kutilities.helpers.data_preparation import print_dataset_statistics, \\\n",
    "labels_to_categories, categories_to_onehot\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from kutilities.callbacks import MetricsCallback, PlottingCallback\n",
    "from kutilities.helpers.data_preparation import get_labels_to_categories_map, \\\n",
    "get_class_weights2, onehot_to_categories\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import scipy.stats\n",
    "import keras\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope, plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading wor2vec and buid embeddings if not in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_file = '../data/datastories.twitter.200d'\n",
    "embedding_file = tmp_file + '.txt'\n",
    "pickle_file = tmp_file + '.pickle'\n",
    "embedding_dim = 200\n",
    "\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        wv_data = pickle.load(f)\n",
    "elif os.path.exists(embedding_file):\n",
    "    print('Indexing file {} ...'.format(embedding_file))\n",
    "    wv_data = {}\n",
    "    with open(embedding_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "            wv_data[word] = coefs\n",
    "    print('Found {} word vectors.'.format(len(wv_data)))\n",
    "\n",
    "    with open(pickle_file, 'wb') as pickle_file:\n",
    "        pickle.dump(wv_data, pickle_file)\n",
    "        \n",
    "wv_data[\"<unk>\"] = np.random.uniform(low=-0.05, high=0.05, size=embedding_dim)\n",
    "wv_data[\"<pad>\"] = np.zeros(embedding_dim)\n",
    "        \n",
    "embeddings = np.zeros((len(wv_data), embedding_dim), dtype=np.float32)\n",
    "wv_id = dict()\n",
    "for i, (w, v) in enumerate(wv_data.items()):\n",
    "    embeddings[i] = v.copy()\n",
    "    wv_id[w] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bulding the ekphrasis text processor with options that interest us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "text_processor = TextPreProcessor(\n",
    "    backoff=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "             'time', 'url', 'date', 'number'],\n",
    "    include_tags={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "                  'emphasis', 'censored'},\n",
    "    fix_html=True,\n",
    "    segmenter=\"twitter\",\n",
    "    corrector=\"twitter\",\n",
    "    unpack_hashtags=True,\n",
    "    unpack_contractions=True,\n",
    "    spell_correct_elong=True,\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize, dicts=[emoticons]\n",
    ")\n",
    "\n",
    "#text_processor.pre_process_doc('the quick brown fox jumped over the lazy dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading train and test data, process resutl for our use (one-hot instead of strings for emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'others' 'happy' 'sad']\n",
      "(2755, 4) (2755,)\n",
      "(30160, 4) (30160,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    turn1                                              turn2  \\\n",
       "id                                                                             \n",
       "0   Don't worry  I'm girl                       hmm how do I know if you are   \n",
       "1             When did I?                         saw many times i think -_-   \n",
       "2                      By                                   by Google Chrome   \n",
       "3          U r ridiculous  I might be ridiculous but I am telling the truth.   \n",
       "4      Just for time pass                         wt do u do 4 a living then   \n",
       "\n",
       "                        turn3   label  \n",
       "id                                     \n",
       "0             What's ur name?  others  \n",
       "1         No. I never saw you   angry  \n",
       "2              Where you live  others  \n",
       "3   U little disgusting whore   angry  \n",
       "4                       Maybe  others  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = []\n",
    "Ytest = []\n",
    "\n",
    "df = pd.read_csv('../data/dev_2019.txt', sep='\\t', index_col=0)\n",
    "Xtest = [df.turn1.values, df.turn2.values, df.turn3.values]\n",
    "Ytest = list(map(lambda x: {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}[x], df.label.values))\n",
    "Ytest = np_utils.to_categorical(Ytest)\n",
    "\n",
    "print(df.label.unique())\n",
    "print(Ytest.shape, Xtest[0].shape)\n",
    "\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "df = pd.read_csv('../data/train.txt', sep='\\t', index_col=0)\n",
    "Xtrain = [df.turn1.values, df.turn2.values, df.turn3.values]\n",
    "\n",
    "Ytrain = list(map(lambda x: {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}[x], df.label.values))\n",
    "Ytrain = np_utils.to_categorical(Ytrain)\n",
    "\n",
    "print(Ytrain.shape, Xtrain[0].shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5509,)\n"
     ]
    }
   ],
   "source": [
    "Xres = []\n",
    "Yres = []\n",
    "\n",
    "df = pd.read_csv('../data/testwithoutlabels.txt', sep='\\t', index_col=0)\n",
    "Xres = [df.turn1.values, df.turn2.values, df.turn3.values]\n",
    "\n",
    "print(Xres[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process text processing to all of our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 34, 145]\n"
     ]
    }
   ],
   "source": [
    "def proces(s):\n",
    "    return text_processor.pre_process_doc(s)\n",
    "\n",
    "with Pool(processes=4) as pool:\n",
    "    Xtrain[0] = list(pool.map(proces, Xtrain[0]))\n",
    "    Xtrain[1] = list(pool.map(proces, Xtrain[1]))\n",
    "    Xtrain[2] = list(pool.map(proces, Xtrain[2]))\n",
    "    Xtest[0] = list(pool.map(proces, Xtest[0]))\n",
    "    Xtest[1] = list(pool.map(proces, Xtest[1]))\n",
    "    Xtest[2] = list(pool.map(proces, Xtest[2]))\n",
    "    Xres[0] = list(pool.map(proces, Xres[0]))\n",
    "    Xres[1] = list(pool.map(proces, Xres[1]))\n",
    "    Xres[2] = list(pool.map(proces, Xres[2]))\n",
    "    max_len_0 = len(max(Xtrain[0], key=len))\n",
    "    max_len_1 = len(max(Xtrain[1], key=len))\n",
    "    max_len_2 = len(max(Xtrain[2], key=len))\n",
    "    \n",
    "max_len = [max_len_0, max_len_1, max_len_2]\n",
    "print(max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check sentece length for cut the to longs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "h = [defaultdict(int), defaultdict(int), defaultdict(int)]\n",
    "\n",
    "for i, tur in enumerate(Xtrain):\n",
    "    for sen in tur:\n",
    "        h[i][len(sen)] += 1\n",
    "    l_count = [h[i][x] for x in range(max_len[i] + 1)]\n",
    "    plt.subplot(1,3,i + 1)\n",
    "    plt.title('turn {}'.format(i + 1))\n",
    "    plt.plot(range(max_len[i] + 1), l_count)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "max_len = [40, 34, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- replace words by there ids of the embeddings and add padding and check how many words are unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30160, 40)\n",
      "2265 / 483015\n",
      "(2755, 40)\n",
      "210 / 42792\n"
     ]
    }
   ],
   "source": [
    "count_unk = 0\n",
    "known = 0\n",
    "for i in range(len(Xtrain)):\n",
    "    for j in range(len(Xtrain[i])):\n",
    "        for k in range(len(Xtrain[i][j])):\n",
    "            if Xtrain[i][j][k] not in wv_data.keys():\n",
    "                Xtrain[i][j][k] = wv_id['<unk>']\n",
    "                count_unk += 1\n",
    "            else:\n",
    "                Xtrain[i][j][k] = wv_id[Xtrain[i][j][k]]\n",
    "                known += 1\n",
    "        Xtrain[i][j] = Xtrain[i][j][:max_len[i]]\n",
    "        Xtrain[i][j] += [wv_id['<pad>']] * (max_len[i] - len(Xtrain[i][j]))\n",
    "    Xtrain[i] = np.array(Xtrain[i])\n",
    "print(Xtrain[0].shape)\n",
    "\n",
    "print(count_unk, '/', count_unk + known)\n",
    "\n",
    "\n",
    "count_unk = 0\n",
    "known = 0\n",
    "for i in range(len(Xtest)):\n",
    "    for j in range(len(Xtest[i])):\n",
    "        for k in range(len(Xtest[i][j])):\n",
    "            if Xtest[i][j][k] not in wv_data.keys():\n",
    "                Xtest[i][j][k] = wv_id['<unk>']\n",
    "                count_unk += 1\n",
    "            else:\n",
    "                Xtest[i][j][k] = wv_id[Xtest[i][j][k]]\n",
    "                known += 1\n",
    "        Xtest[i][j] = Xtest[i][j][:max_len[i]]\n",
    "        Xtest[i][j] += [wv_id['<pad>']] * (max_len[i] - len(Xtest[i][j]))\n",
    "    Xtest[i] = np.array(Xtest[i])\n",
    "print(Xtest[0].shape)\n",
    "print(count_unk, '/', count_unk + known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5509, 40)\n",
      "445 / 85197\n"
     ]
    }
   ],
   "source": [
    "count_unk = 0\n",
    "known = 0\n",
    "for i in range(len(Xres)):\n",
    "    for j in range(len(Xres[i])):\n",
    "        for k in range(len(Xres[i][j])):\n",
    "            if Xres[i][j][k] not in wv_data.keys():\n",
    "                Xres[i][j][k] = wv_id['<unk>']\n",
    "                count_unk += 1\n",
    "            else:\n",
    "                Xres[i][j][k] = wv_id[Xres[i][j][k]]\n",
    "                known += 1\n",
    "        Xres[i][j] = Xres[i][j][:max_len[i]]\n",
    "        Xres[i][j] += [wv_id['<pad>']] * (max_len[i] - len(Xres[i][j]))\n",
    "    Xres[i] = np.array(Xres[i])\n",
    "print(Xres[0].shape)\n",
    "\n",
    "print(count_unk, '/', count_unk + known)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xtrain\n",
    "y_train = Ytrain\n",
    "X_test = Xtest\n",
    "y_test = Ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- function for plot history of a training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def generate_plot(H, nb_epoch):\n",
    "    print(\"Generating plots...\")\n",
    "    sys.stdout.flush()\n",
    "    matplotlib.use(\"Agg\")\n",
    "    matplotlib.pyplot.style.use(\"ggplot\")\n",
    "    matplotlib.pyplot.figure()\n",
    "    N = nb_epoch\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    matplotlib.pyplot.title(\"Training Loss on diabetic retinopathy detection\")\n",
    "    matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "    matplotlib.pyplot.ylabel(\"Loss\")\n",
    "    matplotlib.pyplot.legend(loc=\"lower left\")\n",
    "\n",
    "    matplotlib.pyplot.figure()\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    matplotlib.pyplot.title(\"Training Accuracy on diabetic retinopathy detection\")\n",
    "    matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "    matplotlib.pyplot.ylabel(\"Accuracy\")\n",
    "    matplotlib.pyplot.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check distribution between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 14948, 1: 5506, 2: 5463, 3: 4243}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train = np.asarray(Ytrain).argmax(axis=-1)\n",
    "unique, counts = np.unique(tmp_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- function for create a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN(unit=LSTM, cells=64, bi=False, return_sequences=True, dropout_U=0.,\n",
    "            consume_less='cpu', l2_reg=0):\n",
    "    rnn = unit(cells, return_sequences=return_sequences,\n",
    "               consume_less=consume_less, dropout_U=dropout_U,\n",
    "               W_regularizer=l2(l2_reg))\n",
    "    if bi:\n",
    "        return Bidirectional(rnn)\n",
    "    else:\n",
    "        return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2emotion = {0:\"others\", 1:\"angry\", 2: \"sad\", 3:\"happy\"}\n",
    "emotion2label = {0: 'others', 1: 'angry', 2: 'sad', 3: 'happy'}\n",
    "def getMetrics(predictions, ground, verbose=False):\n",
    "    \"\"\"Given predicted labels and the respective ground truth labels, display some metrics\n",
    "    Input: shape [# of samples, NUM_CLASSES]\n",
    "        predictions : Model output. Every row has 4 decimal values, with the highest belonging to the predicted class\n",
    "        ground : Ground truth labels, converted to one-hot encodings. A sample belonging to Happy class will be [0, 1, 0, 0]\n",
    "    Output:\n",
    "        accuracy : Average accuracy\n",
    "        microPrecision : Precision calculated on a micro level. Ref - https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n",
    "        microRecall : Recall calculated on a micro level\n",
    "        microF1 : Harmonic mean of microPrecision and microRecall. Higher value implies better classification  \n",
    "    \"\"\"\n",
    "    # [0.1, 0.3 , 0.2, 0.1] -> [0, 1, 0, 0]\n",
    "    discretePredictions = to_categorical(predictions.argmax(axis=1))\n",
    "    \n",
    "    truePositives = np.sum(discretePredictions*ground, axis=0)\n",
    "    falsePositives = np.sum(np.clip(discretePredictions - ground, 0, 1), axis=0)\n",
    "    falseNegatives = np.sum(np.clip(ground-discretePredictions, 0, 1), axis=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"True Positives per class : \", truePositives)\n",
    "        print(\"False Positives per class : \", falsePositives)\n",
    "        print(\"False Negatives per class : \", falseNegatives)\n",
    "    \n",
    "    # ------------- Macro level calculation ---------------\n",
    "    macroPrecision = 0\n",
    "    macroRecall = 0\n",
    "    # We ignore the \"Others\" class during the calculation of Precision, Recall and F1\n",
    "    for c in range(1, predictions.shape[1]):\n",
    "        precision = truePositives[c] / (truePositives[c] + falsePositives[c])\n",
    "        macroPrecision += precision\n",
    "        recall = truePositives[c] / (truePositives[c] + falseNegatives[c])\n",
    "        macroRecall += recall\n",
    "        f1 = ( 2 * recall * precision ) / (precision + recall) if (precision+recall) > 0 else 0\n",
    "        if verbose:\n",
    "            print(\"Class %s : Precision : %.3f, Recall : %.3f, F1 : %.3f\" % (label2emotion[c], precision, recall, f1))\n",
    "    \n",
    "    macroPrecision /= 3\n",
    "    macroRecall /= 3\n",
    "    macroF1 = (2 * macroRecall * macroPrecision ) / (macroPrecision + macroRecall) if (macroPrecision+macroRecall) > 0 else 0\n",
    "    if verbose:\n",
    "        print(\"Ignoring the Others class, Macro Precision : %.4f, Macro Recall : %.4f, Macro F1 : %.4f\" % (macroPrecision, macroRecall, macroF1))   \n",
    "    \n",
    "    # ------------- Micro level calculation ---------------\n",
    "    truePositives = truePositives[1:].sum()\n",
    "    falsePositives = falsePositives[1:].sum()\n",
    "    falseNegatives = falseNegatives[1:].sum()    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Ignoring the Others class, Micro TP : %d, FP : %d, FN : %d\" % (truePositives, falsePositives, falseNegatives))\n",
    "    \n",
    "    microPrecision = truePositives / (truePositives + falsePositives)\n",
    "    microRecall = truePositives / (truePositives + falseNegatives)\n",
    "    \n",
    "    microF1 = ( 2 * microRecall * microPrecision ) / (microPrecision + microRecall) if (microPrecision+microRecall) > 0 else 0\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    ground = ground.argmax(axis=1)\n",
    "    accuracy = np.mean(predictions==ground)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Accuracy : %.4f, Micro Precision : %.4f, Micro Recall : %.4f, Micro F1 : %.4f\" % (accuracy, microPrecision, microRecall, microF1))\n",
    "    return accuracy, microPrecision, microRecall, microF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create call back function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}\n",
    "\n",
    "metrics = {\n",
    "    \"f1_pn\": (lambda y_test, y_pred:\n",
    "              f1_score(y_test, y_pred, average='micro',\n",
    "                       labels=[dic['happy'],\n",
    "                               dic['sad'],\n",
    "                               dic['angry'],\n",
    "                               dic['others']])),\n",
    "    \"M_recall\": (\n",
    "        lambda y_test, y_pred: recall_score(y_test, y_pred, average='micro')),\n",
    "    \"M_precision\": (\n",
    "        lambda y_test, y_pred: precision_score(y_test, y_pred,\n",
    "                                               average='micro')),\n",
    "    \"pearson\": (\n",
    "        lambda y_test, y_pred: scipy.stats.pearsonr(y_test, y_pred)[0]),\n",
    "    \"f1\": (\n",
    "        lambda y_test, y_pred: getMetrics(to_categorical(y_test), to_categorical(y_pred))[3])\n",
    "}\n",
    "\n",
    "\n",
    "plotting = PlottingCallback(grid_ranges=(0.5, 0.75), height=5,\n",
    "                            benchmarks={\"SE17\": 0.681})\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/mnt/dd/modelv9.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                               monitor='val.macro_recall', mode=\"max\",\n",
    "                               verbose=1, save_best_only=False)\n",
    "#_callbacks.append(checkpointer)\n",
    "\n",
    "_datasets = {}\n",
    "_datasets[\"1-train\"] = (X_train, y_train)\n",
    "_datasets[\"2-val\"] = (X_test, y_test)\n",
    "_datasets[\"3-test\"] = (Xtest, Ytest)\n",
    "metrics_callback = MetricsCallback(datasets=_datasets, metrics=metrics)\n",
    "    \n",
    "    \n",
    "_callbacks = [metrics_callback, checkpointer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- some data for the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=4\n",
    "max_length=max_len\n",
    "unit=LSTM #LSTM / GRU\n",
    "layers=2\n",
    "cells=64 #150\n",
    "final_size = 100\n",
    "bidirectional=True\n",
    "attention=\"simple\"\n",
    "noise=0.2\n",
    "final_layer=False\n",
    "dropout_final=0.2 #0.4\n",
    "dropout_attention=0.4\n",
    "dropout_words=0.2\n",
    "dropout_rnn=0.2\n",
    "dropout_rnn_U=0.2\n",
    "clipnorm=1\n",
    "lr=0.01 #0.001\n",
    "loss_l2=0.001 #0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=\"context\", kernel_regularizer=<keras.reg..., recurrent_dropout=0.2, implementation=0)`\n",
      "  \"\"\"\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/keras/layers/recurrent.py:2150: UserWarning: `implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n",
      "  warnings.warn('`implementation=0` has been deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 128) (?, ?, 128) (?, ?, 128)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 34)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 40, 200)      131625000   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 34, 200)      131625000   input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 40, 200)      131625000   input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) multiple             135680      embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 128)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 34, 128)      0           bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 40, 128)      0           bidirectional_1[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 114, 128)     0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_1 (Atten (None, 128)          16640       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        attention_with_context_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            132         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 395,037,788\n",
      "Trainable params: 395,037,788\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "shared_RNN = get_RNN(unit, cells, bi=bidirectional, return_sequences='context',\n",
    "                         dropout_U=dropout_rnn_U)\n",
    "\n",
    "\n",
    "input_turn0 = Input(shape=[max_len[0]], dtype='int32')\n",
    "input_turn1 = Input(shape=[max_len[1]], dtype='int32')\n",
    "input_turn2 = Input(shape=[max_len[2]], dtype='int32')\n",
    "\n",
    "\n",
    "# Embeddings\n",
    "turn0_emb = Embedding(\n",
    "    input_dim=embeddings.shape[0],\n",
    "    output_dim=embeddings.shape[1],\n",
    "    input_length=max_len[0],\n",
    "    trainable=True,\n",
    "    mask_zero=True,\n",
    "    weights=[embeddings]\n",
    ")(input_turn0)\n",
    "\n",
    "turn1_emb = Embedding(\n",
    "    input_dim=embeddings.shape[0],\n",
    "    output_dim=embeddings.shape[1],\n",
    "    input_length=max_len[1],\n",
    "    trainable=True,\n",
    "    mask_zero=True,\n",
    "    weights=[embeddings]\n",
    ")(input_turn1)\n",
    "\n",
    "turn2_emb = Embedding(\n",
    "    input_dim=embeddings.shape[0],\n",
    "    output_dim=embeddings.shape[1],\n",
    "    input_length=max_len[2],\n",
    "    trainable=True,\n",
    "    mask_zero=True,\n",
    "    weights=[embeddings]\n",
    ")(input_turn2)\n",
    "\n",
    "\n",
    "# Recurrent NN\n",
    "h_turn0 = shared_RNN(turn0_emb)\n",
    "h_turn0 = Dropout(dropout_rnn_U)(h_turn0)\n",
    "\n",
    "\n",
    "h_turn1 = shared_RNN(turn1_emb)\n",
    "h_turn1 = Dropout(dropout_rnn_U)(h_turn1)\n",
    "\n",
    "\n",
    "h_turn2 = shared_RNN(turn2_emb)\n",
    "h_turn2 = Dropout(dropout_rnn_U)(h_turn2)\n",
    "\n",
    "\n",
    "print(h_turn0.shape, h_turn1.shape, h_turn2.shape)\n",
    "\n",
    "representation = concatenate([h_turn0, h_turn1, h_turn2], axis=1)\n",
    "representation = AttentionWithContext()(representation)\n",
    "representation = Dense(64, activation='linear')(representation)\n",
    "representation = Dropout(dropout_final)(representation)\n",
    "\n",
    "representation = Dense(32, activation='linear')(representation)\n",
    "representation = Dropout(dropout_final)(representation)\n",
    "\n",
    "\n",
    "probabilities = Dense(classes, activation=\"softmax\", activity_regularizer=l2(loss_l2))(representation)\n",
    "\n",
    "model = Model(input=[input_turn0, input_turn1, input_turn2], output=probabilities)\n",
    "\n",
    "model.compile(optimizer=Adam(clipnorm=clipnorm, lr=lr),\n",
    "              loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:105: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 131625000 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[] and type int32 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node bidirectional_1_2/while/Merge_1}} = Merge[N=2, T=DT_INT32, _class=[\"loc:@bidirectional_1_2/while/Switch_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](bidirectional_1_2/while/Enter_1, bidirectional_1_2/while/NextIteration_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c0aa43efc68c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m H = model.fit(X_train, y_train, epochs=nb_epoch, batch_size=100, validation_data=(X_test, y_test),\n\u001b[0;32m----> 3\u001b[0;31m               callbacks=_callbacks);\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dlnlp/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/dlnlp/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnlp/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dlnlp/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    527\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[] and type int32 on /job:localhost/replica:0/task:0/device:CPU:0 by allocator mklcpu\n\t [[{{node bidirectional_1_2/while/Merge_1}} = Merge[N=2, T=DT_INT32, _class=[\"loc:@bidirectional_1_2/while/Switch_1\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](bidirectional_1_2/while/Enter_1, bidirectional_1_2/while/NextIteration_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 7\n",
    "H = model.fit(X_train, y_train, epochs=nb_epoch, batch_size=100, validation_data=(X_test, y_test),\n",
    "              callbacks=_callbacks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot(H, nb_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a model, print metrics and save it as required format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/keras/engine/saving.py:327: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "loaded_model = None\n",
    "with CustomObjectScope({'Attention': Attention, 'AttentionWithContext': AttentionWithContext}):\n",
    "    loaded_model = load_model('/mnt/dd/modelv6.04-0.47.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 34)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 40, 100)      65812500    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 34, 100)      65812500    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 40, 100)      65812500    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) multiple             84480       embedding_1[0][0]                \n",
      "                                                                 embedding_2[0][0]                \n",
      "                                                                 embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 128)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 34, 128)      0           bidirectional_1[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 40, 128)      0           bidirectional_1[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 114, 128)     0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_1 (Atten (None, 128)          16640       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        attention_with_context_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            132         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 197,549,088\n",
      "Trainable params: 197,549,088\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5509, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = loaded_model.predict(Xres)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives per class :  [2111.8643    121.84339    91.2878    103.740875]\n",
      "False Positives per class :  [226.13838   28.156614  33.712208  38.25909 ]\n",
      "False Negatives per class :  [ 82.5685   114.306816  46.931156  82.45989 ]\n",
      "Class angry : Precision : 0.812, Recall : 0.516, F1 : 0.631\n",
      "Class sad : Precision : 0.730, Recall : 0.660, F1 : 0.694\n",
      "Class happy : Precision : 0.731, Recall : 0.557, F1 : 0.632\n",
      "Ignoring the Others class, Macro Precision : 0.7577, Macro Recall : 0.5779, Macro F1 : 0.6557\n",
      "Ignoring the Others class, Micro TP : 316, FP : 100, FN : 243\n",
      "Accuracy : 0.9013, Micro Precision : 0.7599, Micro Recall : 0.5653, Micro F1 : 0.6483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9012704174228675, 0.7598851, 0.5652677, 0.6482852216741343)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "dic = {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}\n",
    "\n",
    "getMetrics(Ytest, res, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_inv = {0: 'others', 1: 'angry', 2: 'sad', 3: 'happy'}\n",
    "res_txt = [dic_inv[np.argmax(r)] for r in res]\n",
    "df = pd.read_csv('../data/testwithoutlabels.txt', sep='\\t', index_col=0)\n",
    "df['label'] = res_txt\n",
    "df.head()\n",
    "df.to_csv('../res.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlnlp)",
   "language": "python",
   "name": "dlnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
