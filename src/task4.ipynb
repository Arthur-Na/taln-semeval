{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/arthur/anaconda3/envs/dlnlp/lib/python3.6/site-packages/kutilities/callbacks.py:6: UserWarning: matplotlib.pyplot as already been imported, this call will have no effect.\n",
      "  matplotlib.use('TkAgg')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.constraints import maxnorm\n",
    "from keras.engine import Input\n",
    "from keras.engine import Model\n",
    "from keras.layers import Dropout, Dense, Bidirectional, LSTM, \\\n",
    "    Embedding, GaussianNoise, Activation, Flatten, \\\n",
    "    RepeatVector, MaxoutDense, GlobalMaxPooling1D, \\\n",
    "    Convolution1D, MaxPooling1D, concatenate, Conv1D, GRU, Flatten, MaxPool1D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from kutilities.layers import AttentionWithContext, Attention, MeanOverTime\n",
    "from kutilities.helpers.data_preparation import print_dataset_statistics, \\\n",
    "labels_to_categories, categories_to_onehot\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from kutilities.callbacks import MetricsCallback, PlottingCallback\n",
    "from kutilities.helpers.data_preparation import get_labels_to_categories_map, \\\n",
    "get_class_weights2, onehot_to_categories\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import scipy.stats\n",
    "import keras\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.utils import CustomObjectScope, plot_model\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading wor2vec and buid embeddings if not in data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_file = '../data/datastories.twitter.100d'\n",
    "embedding_file = tmp_file + '.txt'\n",
    "pickle_file = tmp_file + '.pickle'\n",
    "embedding_dim = 100\n",
    "\n",
    "if os.path.exists(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        wv_data = pickle.load(f)\n",
    "elif os.path.exists(embedding_file):\n",
    "    print('Indexing file {} ...'.format(embedding_file))\n",
    "    wv_data = {}\n",
    "    with open(embedding_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "\n",
    "            wv_data[word] = coefs\n",
    "    print('Found {} word vectors.'.format(len(wv_data)))\n",
    "\n",
    "    with open(pickle_file, 'wb') as pickle_file:\n",
    "        pickle.dump(wv_data, pickle_file)\n",
    "        \n",
    "wv_data[\"<unk>\"] = np.random.uniform(low=-0.05, high=0.05, size=embedding_dim)\n",
    "wv_data[\"<pad>\"] = np.zeros(embedding_dim)\n",
    "        \n",
    "embeddings = np.zeros((len(wv_data), embedding_dim), dtype=np.float32)\n",
    "wv_id = dict()\n",
    "for i, (w, v) in enumerate(wv_data.items()):\n",
    "    embeddings[i] = v.copy()\n",
    "    wv_id[w] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bulding the ekphrasis text processor with options that interest us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    }
   ],
   "source": [
    "text_processor = TextPreProcessor(\n",
    "    backoff=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "             'time', 'url', 'date', 'number'],\n",
    "    include_tags={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "                  'emphasis', 'censored'},\n",
    "    fix_html=True,\n",
    "    segmenter=\"twitter\",\n",
    "    corrector=\"twitter\",\n",
    "    unpack_hashtags=True,\n",
    "    unpack_contractions=True,\n",
    "    spell_correct_elong=True,\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize, dicts=[emoticons]\n",
    ")\n",
    "\n",
    "#text_processor.pre_process_doc('the quick brown fox jumped over the lazy dog')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading train and test data, process resutl for our use (one-hot instead of strings for emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angry' 'others' 'happy' 'sad']\n",
      "(2755, 4) (2755,)\n",
      "['others' 'angry' 'sad' 'happy']\n",
      "(30160, 4) (30160,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turn1</th>\n",
       "      <th>turn2</th>\n",
       "      <th>turn3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't worry  I'm girl</td>\n",
       "      <td>hmm how do I know if you are</td>\n",
       "      <td>What's ur name?</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did I?</td>\n",
       "      <td>saw many times i think -_-</td>\n",
       "      <td>No. I never saw you</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>By</td>\n",
       "      <td>by Google Chrome</td>\n",
       "      <td>Where you live</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U r ridiculous</td>\n",
       "      <td>I might be ridiculous but I am telling the truth.</td>\n",
       "      <td>U little disgusting whore</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just for time pass</td>\n",
       "      <td>wt do u do 4 a living then</td>\n",
       "      <td>Maybe</td>\n",
       "      <td>others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    turn1                                              turn2  \\\n",
       "id                                                                             \n",
       "0   Don't worry  I'm girl                       hmm how do I know if you are   \n",
       "1             When did I?                         saw many times i think -_-   \n",
       "2                      By                                   by Google Chrome   \n",
       "3          U r ridiculous  I might be ridiculous but I am telling the truth.   \n",
       "4      Just for time pass                         wt do u do 4 a living then   \n",
       "\n",
       "                        turn3   label  \n",
       "id                                     \n",
       "0             What's ur name?  others  \n",
       "1         No. I never saw you   angry  \n",
       "2              Where you live  others  \n",
       "3   U little disgusting whore   angry  \n",
       "4                       Maybe  others  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = []\n",
    "Ytest = []\n",
    "\n",
    "df = pd.read_csv('../data/dev_2019.txt', sep='\\t', index_col=0)\n",
    "Xtest = [df.turn1.values, df.turn2.values, df.turn3.values]\n",
    "Ytest = list(map(lambda x: {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}[x], df.label.values))\n",
    "Ytest = np_utils.to_categorical(Ytest)\n",
    "\n",
    "print(df.label.unique())\n",
    "print(Ytest.shape, Xtest[0].shape)\n",
    "\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "\n",
    "df = pd.read_csv('../data/train.txt', sep='\\t', index_col=0)\n",
    "Xtrain = [df.turn1.values, df.turn2.values, df.turn3.values]\n",
    "\n",
    "Ytrain = list(map(lambda x: {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}[x], df.label.values))\n",
    "Ytrain = np_utils.to_categorical(Ytrain)\n",
    "\n",
    "print(Ytrain.shape, Xtrain[0].shape)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- process text processing to all of our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73, 34, 145]\n"
     ]
    }
   ],
   "source": [
    "def proces(s):\n",
    "    return text_processor.pre_process_doc(s)\n",
    "\n",
    "with Pool(processes=4) as pool:\n",
    "    Xtrain[0] = list(pool.map(proces, Xtrain[0]))\n",
    "    Xtrain[1] = list(pool.map(proces, Xtrain[1]))\n",
    "    Xtrain[2] = list(pool.map(proces, Xtrain[2]))\n",
    "    Xtest[0] = list(pool.map(proces, Xtest[0]))\n",
    "    Xtest[1] = list(pool.map(proces, Xtest[1]))\n",
    "    Xtest[2] = list(pool.map(proces, Xtest[2]))\n",
    "    max_len_0 = len(max(Xtrain[0], key=len))\n",
    "    max_len_1 = len(max(Xtrain[1], key=len))\n",
    "    max_len_2 = len(max(Xtrain[2], key=len))\n",
    "    \n",
    "max_len = [max_len_0, max_len_1, max_len_2]\n",
    "print(max_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check sentece length for cut the to longs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/matplotlib/font_manager.py:1241: UserWarning: findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "h = [defaultdict(int), defaultdict(int), defaultdict(int)]\n",
    "\n",
    "for i, tur in enumerate(Xtrain):\n",
    "    for sen in tur:\n",
    "        h[i][len(sen)] += 1\n",
    "    l_count = [h[i][x] for x in range(max_len[i] + 1)]\n",
    "    plt.subplot(1,3,i + 1)\n",
    "    plt.plot(range(max_len[i] + 1), l_count)\n",
    "    plt.yscale('log')\n",
    "    \n",
    "max_len = [40, 34, 40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- replace words by there ids of the embeddings and add padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30160, 40)\n",
      "2265 / 483015\n",
      "(2755, 40)\n",
      "210 / 42792\n"
     ]
    }
   ],
   "source": [
    "count_unk = 0\n",
    "known = 0\n",
    "for i in range(len(Xtrain)):\n",
    "    for j in range(len(Xtrain[i])):\n",
    "        for k in range(len(Xtrain[i][j])):\n",
    "            if Xtrain[i][j][k] not in wv_data.keys():\n",
    "                Xtrain[i][j][k] = wv_id['<unk>']\n",
    "                count_unk += 1\n",
    "            else:\n",
    "                Xtrain[i][j][k] = wv_id[Xtrain[i][j][k]]\n",
    "                known += 1\n",
    "        Xtrain[i][j] = Xtrain[i][j][:max_len[i]]\n",
    "        Xtrain[i][j] += [wv_id['<pad>']] * (max_len[i] - len(Xtrain[i][j]))\n",
    "    Xtrain[i] = np.array(Xtrain[i])\n",
    "print(Xtrain[0].shape)\n",
    "\n",
    "print(count_unk, '/', count_unk + known)\n",
    "\n",
    "\n",
    "count_unk = 0\n",
    "known = 0\n",
    "for i in range(len(Xtest)):\n",
    "    for j in range(len(Xtest[i])):\n",
    "        for k in range(len(Xtest[i][j])):\n",
    "            if Xtest[i][j][k] not in wv_data.keys():\n",
    "                Xtest[i][j][k] = wv_id['<unk>']\n",
    "                count_unk += 1\n",
    "            else:\n",
    "                Xtest[i][j][k] = wv_id[Xtest[i][j][k]]\n",
    "                known += 1\n",
    "        Xtest[i][j] = Xtest[i][j][:max_len[i]]\n",
    "        Xtest[i][j] += [wv_id['<pad>']] * (max_len[i] - len(Xtest[i][j]))\n",
    "    Xtest[i] = np.array(Xtest[i])\n",
    "print(Xtest[0].shape)\n",
    "print(count_unk, '/', count_unk + known)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = Xtrain\n",
    "y_train = Ytrain\n",
    "X_test = Xtest\n",
    "y_test = Ytest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "def generate_plot(H, nb_epoch):\n",
    "    print(\"Generating plots...\")\n",
    "    sys.stdout.flush()\n",
    "    matplotlib.use(\"Agg\")\n",
    "    matplotlib.pyplot.style.use(\"ggplot\")\n",
    "    matplotlib.pyplot.figure()\n",
    "    N = nb_epoch\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    matplotlib.pyplot.title(\"Training Loss on diabetic retinopathy detection\")\n",
    "    matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "    matplotlib.pyplot.ylabel(\"Loss\")\n",
    "    matplotlib.pyplot.legend(loc=\"lower left\")\n",
    "\n",
    "    matplotlib.pyplot.figure()\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "    matplotlib.pyplot.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "    matplotlib.pyplot.title(\"Training Accuracy on diabetic retinopathy detection\")\n",
    "    matplotlib.pyplot.xlabel(\"Epoch #\")\n",
    "    matplotlib.pyplot.ylabel(\"Accuracy\")\n",
    "    matplotlib.pyplot.legend(loc=\"lower left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 14948, 1: 5506, 2: 5463, 3: 4243}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_train = np.asarray(Ytrain).argmax(axis=-1)\n",
    "unique, counts = np.unique(tmp_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RNN(unit=LSTM, cells=64, bi=False, return_sequences=True, dropout_U=0.,\n",
    "            consume_less='cpu', l2_reg=0):\n",
    "    rnn = unit(cells, return_sequences=return_sequences,\n",
    "               consume_less=consume_less, dropout_U=dropout_U,\n",
    "               W_regularizer=l2(l2_reg))\n",
    "    if bi:\n",
    "        return Bidirectional(rnn)\n",
    "    else:\n",
    "        return rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2emotion = {0:\"others\", 1:\"angry\", 2: \"sad\", 3:\"happy\"}\n",
    "emotion2label = {0: 'others', 1: 'angry', 2: 'sad', 3: 'happy'}\n",
    "def getMetrics(predictions, ground, verbose=False):\n",
    "    \"\"\"Given predicted labels and the respective ground truth labels, display some metrics\n",
    "    Input: shape [# of samples, NUM_CLASSES]\n",
    "        predictions : Model output. Every row has 4 decimal values, with the highest belonging to the predicted class\n",
    "        ground : Ground truth labels, converted to one-hot encodings. A sample belonging to Happy class will be [0, 1, 0, 0]\n",
    "    Output:\n",
    "        accuracy : Average accuracy\n",
    "        microPrecision : Precision calculated on a micro level. Ref - https://datascience.stackexchange.com/questions/15989/micro-average-vs-macro-average-performance-in-a-multiclass-classification-settin/16001\n",
    "        microRecall : Recall calculated on a micro level\n",
    "        microF1 : Harmonic mean of microPrecision and microRecall. Higher value implies better classification  \n",
    "    \"\"\"\n",
    "    # [0.1, 0.3 , 0.2, 0.1] -> [0, 1, 0, 0]\n",
    "    discretePredictions = to_categorical(predictions.argmax(axis=1))\n",
    "    \n",
    "    truePositives = np.sum(discretePredictions*ground, axis=0)\n",
    "    falsePositives = np.sum(np.clip(discretePredictions - ground, 0, 1), axis=0)\n",
    "    falseNegatives = np.sum(np.clip(ground-discretePredictions, 0, 1), axis=0)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"True Positives per class : \", truePositives)\n",
    "        print(\"False Positives per class : \", falsePositives)\n",
    "        print(\"False Negatives per class : \", falseNegatives)\n",
    "    \n",
    "    # ------------- Macro level calculation ---------------\n",
    "    macroPrecision = 0\n",
    "    macroRecall = 0\n",
    "    # We ignore the \"Others\" class during the calculation of Precision, Recall and F1\n",
    "    for c in range(1, predictions.shape[1]):\n",
    "        precision = truePositives[c] / (truePositives[c] + falsePositives[c])\n",
    "        macroPrecision += precision\n",
    "        recall = truePositives[c] / (truePositives[c] + falseNegatives[c])\n",
    "        macroRecall += recall\n",
    "        f1 = ( 2 * recall * precision ) / (precision + recall) if (precision+recall) > 0 else 0\n",
    "        if verbose:\n",
    "            print(\"Class %s : Precision : %.3f, Recall : %.3f, F1 : %.3f\" % (label2emotion[c], precision, recall, f1))\n",
    "    \n",
    "    macroPrecision /= 3\n",
    "    macroRecall /= 3\n",
    "    macroF1 = (2 * macroRecall * macroPrecision ) / (macroPrecision + macroRecall) if (macroPrecision+macroRecall) > 0 else 0\n",
    "    if verbose:\n",
    "        print(\"Ignoring the Others class, Macro Precision : %.4f, Macro Recall : %.4f, Macro F1 : %.4f\" % (macroPrecision, macroRecall, macroF1))   \n",
    "    \n",
    "    # ------------- Micro level calculation ---------------\n",
    "    truePositives = truePositives[1:].sum()\n",
    "    falsePositives = falsePositives[1:].sum()\n",
    "    falseNegatives = falseNegatives[1:].sum()    \n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Ignoring the Others class, Micro TP : %d, FP : %d, FN : %d\" % (truePositives, falsePositives, falseNegatives))\n",
    "    \n",
    "    microPrecision = truePositives / (truePositives + falsePositives)\n",
    "    microRecall = truePositives / (truePositives + falseNegatives)\n",
    "    \n",
    "    microF1 = ( 2 * microRecall * microPrecision ) / (microPrecision + microRecall) if (microPrecision+microRecall) > 0 else 0\n",
    "    # -----------------------------------------------------\n",
    "    \n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    ground = ground.argmax(axis=1)\n",
    "    accuracy = np.mean(predictions==ground)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Accuracy : %.4f, Micro Precision : %.4f, Micro Recall : %.4f, Micro F1 : %.4f\" % (accuracy, microPrecision, microRecall, microF1))\n",
    "    return accuracy, microPrecision, microRecall, microF1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}\n",
    "\n",
    "metrics = {\n",
    "    \"f1_pn\": (lambda y_test, y_pred:\n",
    "              f1_score(y_test, y_pred, average='micro',\n",
    "                       labels=[dic['happy'],\n",
    "                               dic['sad'],\n",
    "                               dic['angry'],\n",
    "                               dic['others']])),\n",
    "    \"M_recall\": (\n",
    "        lambda y_test, y_pred: recall_score(y_test, y_pred, average='micro')),\n",
    "    \"M_precision\": (\n",
    "        lambda y_test, y_pred: precision_score(y_test, y_pred,\n",
    "                                               average='micro')),\n",
    "    \"pearson\": (\n",
    "        lambda y_test, y_pred: scipy.stats.pearsonr(y_test, y_pred)[0]),\n",
    "    \"f1\": (\n",
    "        lambda y_test, y_pred: getMetrics(to_categorical(y_test), to_categorical(y_pred))[3])\n",
    "}\n",
    "\n",
    "\n",
    "plotting = PlottingCallback(grid_ranges=(0.5, 0.75), height=5,\n",
    "                            benchmarks={\"SE17\": 0.681})\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='/mnt/dd/modelv8.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
    "                               monitor='val.macro_recall', mode=\"max\",\n",
    "                               verbose=1, save_best_only=False)\n",
    "#_callbacks.append(checkpointer)\n",
    "\n",
    "_datasets = {}\n",
    "_datasets[\"1-train\"] = (X_train, y_train)\n",
    "_datasets[\"2-val\"] = (X_test, y_test)\n",
    "_datasets[\"3-test\"] = (Xtest, Ytest)\n",
    "metrics_callback = MetricsCallback(datasets=_datasets, metrics=metrics)\n",
    "    \n",
    "    \n",
    "_callbacks = [metrics_callback, checkpointer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#embeddings = np.array(list(wv_data.values()))\n",
    "classes=4\n",
    "max_length=max_len\n",
    "unit=LSTM #LSTM / GRU\n",
    "layers=2\n",
    "cells=64 #150\n",
    "final_size = 100\n",
    "bidirectional=True\n",
    "attention=\"simple\"\n",
    "noise=0.2\n",
    "final_layer=False\n",
    "dropout_final=0.2 #0.4\n",
    "dropout_attention=0.4\n",
    "dropout_words=0.2\n",
    "dropout_rnn=0.2\n",
    "dropout_rnn_U=0.2\n",
    "clipnorm=1\n",
    "lr=0.01 #0.001\n",
    "loss_l2=0.001 #0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=\"context\", kernel_regularizer=<keras.reg..., recurrent_dropout=0.2, implementation=0)`\n",
      "  \"\"\"\n",
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/keras/layers/recurrent.py:1977: UserWarning: `implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n",
      "  warnings.warn('`implementation=0` has been deprecated, '\n",
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=\"context\", kernel_regularizer=<keras.reg..., recurrent_dropout=0.2, implementation=0)`\n",
      "  \"\"\"\n",
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/keras/layers/recurrent.py:1977: UserWarning: `implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n",
      "  warnings.warn('`implementation=0` has been deprecated, '\n",
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=\"context\", kernel_regularizer=<keras.reg..., recurrent_dropout=0.2, implementation=0)`\n",
      "  \"\"\"\n",
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/keras/layers/recurrent.py:1977: UserWarning: `implementation=0` has been deprecated, and now defaults to `implementation=1`.Please update your layer call.\n",
      "  warnings.warn('`implementation=0` has been deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 128) (?, ?, 128) (?, ?, 128)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 34)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 40, 100)      65812500    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 34, 100)      65812500    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 40, 100)      65812500    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 40, 128)      84480       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 34, 128)      84480       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 40, 128)      84480       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 40, 128)      0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 34, 128)      0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 40, 128)      0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 114, 128)     0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_with_context_1 (Atten (None, 128)          16640       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        attention_with_context_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            132         dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 197,718,048\n",
      "Trainable params: 197,718,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arthur/anaconda3/envs/taln/lib/python3.6/site-packages/ipykernel_launcher.py:68: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "#shared_RNN = get_RNN(unit, cells, bi=bidirectional, return_sequences='context',\n",
    "#                         dropout_U=dropout_rnn_U)\n",
    "\n",
    "\n",
    "input_turn0 = Input(shape=[max_len[0]], dtype='int32')\n",
    "input_turn1 = Input(shape=[max_len[1]], dtype='int32')\n",
    "input_turn2 = Input(shape=[max_len[2]], dtype='int32')\n",
    "\n",
    "\n",
    "# Embeddings\n",
    "turn0_emb = Embedding(\n",
    "    input_dim=embeddings.shape[0],\n",
    "    output_dim=embeddings.shape[1],\n",
    "    input_length=max_len[0],\n",
    "    trainable=True,\n",
    "    mask_zero=True,\n",
    "    weights=[embeddings]\n",
    ")(input_turn0)\n",
    "\n",
    "turn1_emb = Embedding(\n",
    "    input_dim=embeddings.shape[0],\n",
    "    output_dim=embeddings.shape[1],\n",
    "    input_length=max_len[1],\n",
    "    trainable=True,\n",
    "    mask_zero=True,\n",
    "    weights=[embeddings]\n",
    ")(input_turn1)\n",
    "\n",
    "turn2_emb = Embedding(\n",
    "    input_dim=embeddings.shape[0],\n",
    "    output_dim=embeddings.shape[1],\n",
    "    input_length=max_len[2],\n",
    "    trainable=True,\n",
    "    mask_zero=True,\n",
    "    weights=[embeddings]\n",
    ")(input_turn2)\n",
    "\n",
    "\n",
    "# Recurrent NN\n",
    "h_turn0 = get_RNN(unit, cells, bi=bidirectional, return_sequences='context',\n",
    "                         dropout_U=dropout_rnn_U)(turn0_emb)\n",
    "h_turn0 = Dropout(dropout_rnn_U)(h_turn0)\n",
    "\n",
    "\n",
    "h_turn1 = get_RNN(unit, cells, bi=bidirectional, return_sequences='context',\n",
    "                         dropout_U=dropout_rnn_U)(turn1_emb)\n",
    "h_turn1 = Dropout(dropout_rnn_U)(h_turn1)\n",
    "\n",
    "\n",
    "h_turn2 = get_RNN(unit, cells, bi=bidirectional, return_sequences='context',\n",
    "                         dropout_U=dropout_rnn_U)(turn2_emb)\n",
    "h_turn2 = Dropout(dropout_rnn_U)(h_turn2)\n",
    "\n",
    "\n",
    "print(h_turn0.shape, h_turn1.shape, h_turn2.shape)\n",
    "\n",
    "representation = concatenate([h_turn0, h_turn1, h_turn2], axis=1)\n",
    "representation = AttentionWithContext()(representation)\n",
    "representation = Dense(64, activation='linear')(representation)\n",
    "representation = Dropout(dropout_final)(representation)\n",
    "\n",
    "representation = Dense(32, activation='linear')(representation)\n",
    "representation = Dropout(dropout_final)(representation)\n",
    "\n",
    "\n",
    "probabilities = Dense(classes, activation=\"softmax\", activity_regularizer=l2(loss_l2))(representation)\n",
    "\n",
    "model = Model(input=[input_turn0, input_turn1, input_turn2], output=probabilities)\n",
    "\n",
    "model.compile(optimizer=Adam(clipnorm=clipnorm, lr=lr),\n",
    "              loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 30160 samples, validate on 2755 samples\n",
      "Epoch 1/7\n",
      "30100/30160 [============================>.] - ETA: 0s - loss: 0.6401 - mean_absolute_error: 0.1479 - acc: 0.8109         M_precision  M_recall        f1     f1_pn   pearson\n",
      "1-train     0.890915  0.890915  0.875819  0.890915  0.793440\n",
      "2-val       0.889655  0.889655  0.669421  0.889655  0.641413\n",
      "3-test      0.889655  0.889655  0.669421  0.889655  0.641413\n",
      "\n",
      "Epoch 00001: saving model to /mnt/dd/modelv8.01-0.46.hdf5\n",
      "30160/30160 [==============================] - 267s 9ms/step - loss: 0.6398 - mean_absolute_error: 0.1478 - acc: 0.8110 - val_loss: 0.4607 - val_mean_absolute_error: 0.0984 - val_acc: 0.8897 - 1-train.f1_pn: 0.8909 - 1-train.M_recall: 0.8909 - 1-train.M_precision: 0.8909 - 1-train.pearson: 0.7934 - 1-train.f1: 0.8758 - 2-val.f1_pn: 0.8897 - 2-val.M_recall: 0.8897 - 2-val.M_precision: 0.8897 - 2-val.pearson: 0.6414 - 2-val.f1: 0.6694 - 3-test.f1_pn: 0.8897 - 3-test.M_recall: 0.8897 - 3-test.M_precision: 0.8897 - 3-test.pearson: 0.6414 - 3-test.f1: 0.6694\n",
      "Epoch 2/7\n",
      "30100/30160 [============================>.] - ETA: 0s - loss: 0.4028 - mean_absolute_error: 0.0823 - acc: 0.8967         M_precision  M_recall        f1     f1_pn   pearson\n",
      "1-train     0.936273  0.936273  0.928211  0.936273  0.892573\n",
      "2-val       0.873684  0.873684  0.652050  0.873684  0.637204\n",
      "3-test      0.873684  0.873684  0.652050  0.873684  0.637204\n",
      "\n",
      "Epoch 00002: saving model to /mnt/dd/modelv8.02-0.50.hdf5\n",
      "30160/30160 [==============================] - 254s 8ms/step - loss: 0.4026 - mean_absolute_error: 0.0823 - acc: 0.8967 - val_loss: 0.4983 - val_mean_absolute_error: 0.0942 - val_acc: 0.8737 - 1-train.f1_pn: 0.9363 - 1-train.M_recall: 0.9363 - 1-train.M_precision: 0.9363 - 1-train.pearson: 0.8926 - 1-train.f1: 0.9282 - 2-val.f1_pn: 0.8737 - 2-val.M_recall: 0.8737 - 2-val.M_precision: 0.8737 - 2-val.pearson: 0.6372 - 2-val.f1: 0.6520 - 3-test.f1_pn: 0.8737 - 3-test.M_recall: 0.8737 - 3-test.M_precision: 0.8737 - 3-test.pearson: 0.6372 - 3-test.f1: 0.6520\n",
      "Epoch 3/7\n",
      "30100/30160 [============================>.] - ETA: 0s - loss: 0.3158 - mean_absolute_error: 0.0587 - acc: 0.9258         M_precision  M_recall        f1     f1_pn   pearson\n",
      "1-train     0.942341  0.942341  0.933706  0.942341  0.894670\n",
      "2-val       0.892922  0.892922  0.675000  0.892922  0.633731\n",
      "3-test      0.892922  0.892922  0.675000  0.892922  0.633731\n",
      "\n",
      "Epoch 00003: saving model to /mnt/dd/modelv8.03-0.45.hdf5\n",
      "30160/30160 [==============================] - 259s 9ms/step - loss: 0.3156 - mean_absolute_error: 0.0587 - acc: 0.9259 - val_loss: 0.4512 - val_mean_absolute_error: 0.0679 - val_acc: 0.8929 - 1-train.f1_pn: 0.9423 - 1-train.M_recall: 0.9423 - 1-train.M_precision: 0.9423 - 1-train.pearson: 0.8947 - 1-train.f1: 0.9337 - 2-val.f1_pn: 0.8929 - 2-val.M_recall: 0.8929 - 2-val.M_precision: 0.8929 - 2-val.pearson: 0.6337 - 2-val.f1: 0.6750 - 3-test.f1_pn: 0.8929 - 3-test.M_recall: 0.8929 - 3-test.M_precision: 0.8929 - 3-test.pearson: 0.6337 - 3-test.f1: 0.6750\n",
      "Epoch 4/7\n",
      "30100/30160 [============================>.] - ETA: 0s - loss: 0.2681 - mean_absolute_error: 0.0458 - acc: 0.9415         M_precision  M_recall        f1     f1_pn   pearson\n",
      "1-train     0.964755  0.964755  0.959558  0.964755  0.942993\n",
      "2-val       0.889292  0.889292  0.668041  0.889292  0.635735\n",
      "3-test      0.889292  0.889292  0.668041  0.889292  0.635735\n",
      "\n",
      "Epoch 00004: saving model to /mnt/dd/modelv8.04-0.50.hdf5\n",
      "30160/30160 [==============================] - 270s 9ms/step - loss: 0.2681 - mean_absolute_error: 0.0458 - acc: 0.9415 - val_loss: 0.5041 - val_mean_absolute_error: 0.0634 - val_acc: 0.8893 - 1-train.f1_pn: 0.9648 - 1-train.M_recall: 0.9648 - 1-train.M_precision: 0.9648 - 1-train.pearson: 0.9430 - 1-train.f1: 0.9596 - 2-val.f1_pn: 0.8893 - 2-val.M_recall: 0.8893 - 2-val.M_precision: 0.8893 - 2-val.pearson: 0.6357 - 2-val.f1: 0.6680 - 3-test.f1_pn: 0.8893 - 3-test.M_recall: 0.8893 - 3-test.M_precision: 0.8893 - 3-test.pearson: 0.6357 - 3-test.f1: 0.6680\n",
      "Epoch 5/7\n",
      "30100/30160 [============================>.] - ETA: 0s - loss: 0.2437 - mean_absolute_error: 0.0385 - acc: 0.9501         M_precision  M_recall        f1     f1_pn   pearson\n",
      "1-train     0.971253  0.971253  0.966406  0.971253  0.951648\n",
      "2-val       0.885662  0.885662  0.664622  0.885662  0.640694\n",
      "3-test      0.885662  0.885662  0.664622  0.885662  0.640694\n",
      "\n",
      "Epoch 00005: saving model to /mnt/dd/modelv8.05-0.55.hdf5\n",
      "30160/30160 [==============================] - 266s 9ms/step - loss: 0.2441 - mean_absolute_error: 0.0386 - acc: 0.9500 - val_loss: 0.5483 - val_mean_absolute_error: 0.0647 - val_acc: 0.8857 - 1-train.f1_pn: 0.9713 - 1-train.M_recall: 0.9713 - 1-train.M_precision: 0.9713 - 1-train.pearson: 0.9516 - 1-train.f1: 0.9664 - 2-val.f1_pn: 0.8857 - 2-val.M_recall: 0.8857 - 2-val.M_precision: 0.8857 - 2-val.pearson: 0.6407 - 2-val.f1: 0.6646 - 3-test.f1_pn: 0.8857 - 3-test.M_recall: 0.8857 - 3-test.M_precision: 0.8857 - 3-test.pearson: 0.6407 - 3-test.f1: 0.6646\n",
      "Epoch 6/7\n",
      "30100/30160 [============================>.] - ETA: 0s - loss: 0.2229 - mean_absolute_error: 0.0329 - acc: 0.9585         M_precision  M_recall        f1     f1_pn   pearson\n",
      "1-train     0.974237  0.974237  0.969801  0.974237  0.956129\n",
      "2-val       0.893648  0.893648  0.675105  0.893648  0.651288\n",
      "3-test      0.893648  0.893648  0.675105  0.893648  0.651288\n",
      "\n",
      "Epoch 00006: saving model to /mnt/dd/modelv8.06-0.49.hdf5\n",
      "30160/30160 [==============================] - 249s 8ms/step - loss: 0.2227 - mean_absolute_error: 0.0329 - acc: 0.9586 - val_loss: 0.4936 - val_mean_absolute_error: 0.0646 - val_acc: 0.8936 - 1-train.f1_pn: 0.9742 - 1-train.M_recall: 0.9742 - 1-train.M_precision: 0.9742 - 1-train.pearson: 0.9561 - 1-train.f1: 0.9698 - 2-val.f1_pn: 0.8936 - 2-val.M_recall: 0.8936 - 2-val.M_precision: 0.8936 - 2-val.pearson: 0.6513 - 2-val.f1: 0.6751 - 3-test.f1_pn: 0.8936 - 3-test.M_recall: 0.8936 - 3-test.M_precision: 0.8936 - 3-test.pearson: 0.6513 - 3-test.f1: 0.6751\n",
      "Epoch 7/7\n",
      "30100/30160 [============================>.] - ETA: 0s - loss: 0.2056 - mean_absolute_error: 0.0281 - acc: 0.9644         M_precision  M_recall        f1     f1_pn   pearson\n",
      "1-train     0.976459  0.976459  0.972943  0.976459  0.964231\n",
      "2-val       0.884574  0.884574  0.659919  0.884574  0.635595\n",
      "3-test      0.884574  0.884574  0.659919  0.884574  0.635595\n",
      "\n",
      "Epoch 00007: saving model to /mnt/dd/modelv8.07-0.61.hdf5\n",
      "30160/30160 [==============================] - 253s 8ms/step - loss: 0.2054 - mean_absolute_error: 0.0281 - acc: 0.9644 - val_loss: 0.6145 - val_mean_absolute_error: 0.0635 - val_acc: 0.8846 - 1-train.f1_pn: 0.9765 - 1-train.M_recall: 0.9765 - 1-train.M_precision: 0.9765 - 1-train.pearson: 0.9642 - 1-train.f1: 0.9729 - 2-val.f1_pn: 0.8846 - 2-val.M_recall: 0.8846 - 2-val.M_precision: 0.8846 - 2-val.pearson: 0.6356 - 2-val.f1: 0.6599 - 3-test.f1_pn: 0.8846 - 3-test.M_recall: 0.8846 - 3-test.M_precision: 0.8846 - 3-test.pearson: 0.6356 - 3-test.f1: 0.6599\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 7\n",
    "H = model.fit(X_train, y_train, epochs=nb_epoch, batch_size=100, validation_data=(X_test, y_test),\n",
    "              callbacks=_callbacks);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_plot(H, nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = None\n",
    "with CustomObjectScope({'Attention': Attention, 'AttentionWithContext': AttentionWithContext}):\n",
    "    loaded_model = load_model('/mnt/dd/modelv6.04-0.47.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2755, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = loaded_model.predict(Xtest)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_macro: 0.760732223339039\n",
      "M_recall: 0.9012704174228675\n",
      "M_precision: 0.9012704174228675\n",
      "pearson: 0.6701673753893513\n",
      "True Positives per class :  [2111.86130146  121.84337423   91.28779425  103.74091497]\n",
      "False Positives per class :  [226.13869854  28.15662577  33.71220575  38.25908503]\n",
      "False Negatives per class :  [ 82.56849863 114.30691099  46.9312464   82.45996037]\n",
      "Class angry : Precision : 0.812, Recall : 0.516, F1 : 0.631\n",
      "Class sad : Precision : 0.730, Recall : 0.660, F1 : 0.694\n",
      "Class happy : Precision : 0.731, Recall : 0.557, F1 : 0.632\n",
      "Ignoring the Others class, Macro Precision : 0.7577, Macro Recall : 0.5779, Macro F1 : 0.6557\n",
      "Ignoring the Others class, Micro TP : 316, FP : 100, FN : 243\n",
      "Accuracy : 0.9013, Micro Precision : 0.7599, Micro Recall : 0.5653, Micro F1 : 0.6483\n",
      "getMetrics: (0.9012704174228675, 0.7598850922246942, 0.5652674415589133, 0.6482850706011686)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "dic = {'others': 0, 'angry': 1, 'sad': 2, 'happy': 3}\n",
    "\n",
    "getMetrics(Ytest, res, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_inv = {0: 'others', 1: 'angry', 2: 'sad', 3: 'happy'}\n",
    "res_txt = [dic_inv[np.argmax(r)] for r in res]\n",
    "df = pd.read_csv('../data/test.txt', sep='\\t', index_col=0)\n",
    "df['label'] = res_txt\n",
    "df.head()\n",
    "df.to_csv('submit1.txt', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dlnlp)",
   "language": "python",
   "name": "dlnlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
